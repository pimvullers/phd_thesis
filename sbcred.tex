\chapter{Self-Blindable Credentials}

The drawback of using regular public-key certificates, like X.509
certificates~\cite{ISO9594-8}, is that they are inherently traceable. This is
caused by the fixed public key and signature that are contained in the
certificate. The public key can be used as a unique identifier for the user and
is included in the signature, making that identifying as well.

To circumvent this problem Verheul~\cite{Verheul01} proposes a
variant~\cite{BonehLS01,BonehLS04} of the Chaum-Pedersen signature
scheme~\cite{ChaumPedersen93} which allows these values to be randomised, or
\emph{blinded}, such that they are no longer traceable, while the signature can
still be verified. This signature scheme can then be used to implement a
credential system which allows the users themselves to blind their credentials
in order to prevent traceability.

In this chapter we describe the signature schemes and the resulting credential
system as well as our implementations~\cite{BatinaHJMV10,HoepmanJV10}.

\section{Self-Blindable Signatures}

[TODO: brief intro]

\subsection{Chaum-Pedersen Signature Scheme}

Chaum and Pedersen~\cite{ChaumPedersen93} describe a basic signature scheme
which is intended to be used in combination with smart cards. This scheme works
in the discrete logarithm setting and will be used as the basis for the
following schemes.

The public key is a value $h$ together with a description of the prime-order
group in which the computations take place. As an example we use $(p, q, g)$,
which denotes a subgroup of $\Z^*_p$ of prime-order $q$ with generator $g$. The
corresponding private key is $x = \log_g h$.

\begin{algorithm}[t]
  \caption{Generate a Chaum-Pedersen signature.}
  \label{alg:CP-sign}
  \addtolength{\baselineskip}{1mm}
  \begin{algorithmic}[1]
    \Function{CP-sign}{$m, (p, q, g), x$}
      \State $z \gets m^x \mod p$

      \State $a \gets g^s \mod p$
      \State $b \gets m^s \mod p$

      \State $c \gets \Call{Hash}{m, z, a, b}$

      \State $r \gets s + c \cdot x \mod q$

      \Return $(z, a, b, r)$
    \EndFunction
  \end{algorithmic}
\end{algorithm}

The signature over a message $m$ is a single exponentiation with the private key
$z = m^x \mod p$ together with a proof that $\log_g h = \log_m z$. This
signature can be generated using Algorithm~\ref{alg:CP-sign}. Verification of
the signature consists of checking the proof according to
Algorithm~\ref{alg:CP-verify}. When the proof is correct, the verifier is
assured that the message is signed using the private key corresponding to the
public key used for verification.

\begin{algorithm}[t]
  \caption{Verify a Chaum-Pedersen signature.}
  \label{alg:CP-verify}
  \addtolength{\baselineskip}{1mm}
  \begin{algorithmic}[1]
    \Function{CP-verify}{$m, (z, a, b, r), (p, q, g), h$}
      \State $c \gets \Call{Hash}{m, z, a, b}$

      \If{$g^r \neq a \cdot h^c \mod p$}
      \Return \Call{Invalid}{}
      \EndIf

      \If{$m^r \neq b \cdot z^c \mod p$}
      \Return \Call{Invalid}{}
      \EndIf

      \Return \Call{Valid}{}
    \EndFunction
  \end{algorithmic}
\end{algorithm}

\subsection{Boneh-Lynn-Shacham Signature Scheme}

Since the signature scheme of Chaum and Pedersen operates in the discrete
logarithm setting it can also be used with elliptic curve cryptography. Boneh,
Lynn and Shacham~\cite{BonehLS01,BonehLS04} present a signature scheme that
works on elliptic curves with bilinear pairings (see Section~\ref{sec:pairing})
and resembles the scheme by Chaum and Pedersen, but omits the equality proof in
order to achieve short signatures.

At the same time Verheul~\cite{Verheul01} gives a similar description of this
proofless variant of the Chaum-Pedersen scheme for groups in which the
decisional Diffie-Hellman problem is easy while the computational Diffie-Hellman
and discrete logarithm problems are hard. Elliptic curves with bilinear pairings
provide such groups. The proof of equality can in this case be substituted by a
pairing equation to be checked by the verifier.

The public key is a point $Q = x \cdot P_2$ on an elliptic curve $E_2$ together
with a description of that curve. The private key is the scalar value $x$. To
sign a message $m$ the signer transforms this into a point $P_m$ on the curve
$E_1$ which is simply multiplied with the private key as described in
Algorithm~\ref{alg:BLS-sign}.

[TODO: Note that $P_2$ is a system parameter]

\begin{algorithm}[t]
  \caption{Generate a Boneh-Lynn-Shacham signature.}
  \label{alg:BLS-sign}
  \addtolength{\baselineskip}{1mm}
  \begin{algorithmic}[1]
    \Function{BLS-sign}{$m, E_1, x$}
      \State $P_m \gets \Call{HashToPoint}{E_1, m}$
      \State $Z \gets x \cdot P_m$

      \Return $Z$
    \EndFunction
  \end{algorithmic}
\end{algorithm}

To verify the signature (Algorithm~\ref{alg:BLS-verify}) the verifier has to
perform the same check as with the Chaum-Pedersen scheme, that is, whether the
private key used to generate the signature corresponds to the public key.
Instead of using a proof, this can be achieved by checking the following
equation:
\begin{equation}\label{eqn:BLS-verify}
  e(P_m, Q) = e(P_m, x \cdot P_2) = e(x \cdot P_m, P_2) = e(Z, P_2)
\end{equation}
where $e: E_1 \times E_2 \to G$ is a bilinear pairing as described in
Section~\ref{sec:pairing}.

\begin{algorithm}[t]
  \caption{Verify a Boneh-Lynn-Shacham signature.}
  \label{alg:BLS-verify}
  \addtolength{\baselineskip}{1mm}
  \begin{algorithmic}[1]
    \Function{BLS-verify}{$m, Z, E_1, Q$}
      \State $P_m \gets \Call{HashToPoint}{E_1, m}$
      \If{$e(P_m, Q) \neq e(Z, P_2)$}
      \Return \Call{Invalid}{}
      \EndIf

      \Return \Call{Valid}{}
    \EndFunction
  \end{algorithmic}
\end{algorithm}

Verheul~\cite{Verheul01} points out a powerful aspect about these signatures,
they are invariant under blinding. When this signature is used to sign points on
the curve there is no need to transform the message to a point, such that the
\textsc{HashToPoint} operation can be omitted. Now the user can choose an
arbitrary number $b$ as blinding factor, and multiply both the message and
signature with this factor. The resulting pair
$(b \cdot P_m, b \cdot (x \cdot P_m))$ can still be verified using the
verification equation (\ref{eqn:BLS-verify}):
$$e(b \cdot P_m, Q) = e(b \cdot P_m, x \cdot P_2) =
e(b \cdot x \cdot P_m, P_2) = e(b \cdot Z, P_2)$$
Hence the signature remains valid. Since the user can perform this blinding all
by itself Verheul calls these signatures \emph{self-blindable}.

[TODO: add a reference to Algorithm~\ref{alg:BLS-verify}]

\section{Verheul's Self-Blindable Certificates}

Verheul proposes to use the self-blindable signatures to construct public-key
certificates which allow the user to randomise its public key pair and the
corresponding certificate. Such certificates can be used to circumvent
traceability based on the public key and signature. A certificate of a user
public key $P_U$ from an identity provider with public verification key $P_{ID}$
takes the form
\begin{equation}\label{eqn:SB-certificate}
  \{ P_U, Sig(P_U, s_{ID}) \}\text,
\end{equation}
where $s_{ID}$ is the private signing key of the identity provider corresponding
to $P_{ID}$.

\subsection{Credential Certificates}

Credential certificates are digital certificates that bind credentials to users
known by a public key. Proof of credential possession is given by proving
possession of the private key related to the public key referenced in the
certificate.

$$\{P_U, [Sig(P_U, s_C), Cert(P_C, \text{"Credential Issuer statement"})]\}$$

Here, the public key $P_U$ of the user is signed using a private key $s_C$ of
the credential issuer. The corresponding public key $P_C$ of the credential
issuer is included in a (conventional PKI) certificate which contains the
statement corresponding to this public key.

When we consider only a single statement per public key, these certificates can
be stored in a public database and can be omitted from the credential, given
that the corresponding public key can be identified. This allows the credentials
to be compact which is beneficial for devices with limited storage capacities,
like smart cards.

To summarise, a credential certificate will consist of
\begin{itemize}
  \item the user's public key $P_U$,
  \item a signature $Sig(P_U, s_{Cx}) = s_{Cx} \cdot P_U$ over the public key
    using the credential signing key $s_{Cx}$, and
  \item a reference to the credential statement $x$.
\end{itemize}
The database will then contain
\begin{itemize}
  \item a reference $x$,
  \item the public verification key $P_{Cx}$ corresponding to $s_{Cx}$, and
  \item the credential statement.
\end{itemize}

\noindent [TODO: switch to smart card context, this context should be described
in the introduction, and this should mainly be a reference]

\section{Credential Issuance}

\begin{figure}[ht]
  \centering
  \includegraphics[scale=.4]{mscs/sbc_issuance}
  \caption{Issuance of self-blindable credential certificates.}
  \label{fig:SBC-issuance}
\end{figure}

To obtain a credential from a credential issuer the cardholder must provide the
issuer with its public key and proof possession of the corresponding private key.
This public key can be signed by an identity provider in order to increase the
trust level of the system. When the credential issuer has verified the
authenticity of the user he will verify eligibility for the requested attribute.
Once this has been verified the issuer signs the user's public key using the
private key corresponding to the requested attribute and send this signature to
the user as depicted in Figure~\ref{fig:SBC-issuance}.

\section{Credential Verification}

\begin{figure}[ht]
  \centering
  \includegraphics[scale=.4]{mscs/sbc_verification}
  \caption{Verification of self-blindable credential certificates.}
  \label{fig:SBC-verification}
\end{figure}

When the user wants to utilise an attribute stored in a credential it has to
show the credential to the service provider. To prevent the service provider
from tracing her based on the public key the user first blinds her key pair and
the credential as shown in Figure~\ref{fig:SBC-verification}. Next she sends
the results from this blinding operation to the service provider and proofs
possession of the (blinded) private key. This last step is easily achieved by
signing a challenge received from the service provider using this private key.
The service provider can then verify this signature using the public key it
received earlier.

\section{Smart Card Implementation}

To understand the practical limitations and estimate the performance of our
protocols, we implemented the protocol from Figure~\ref{fig:SBC-verification}
in Java (terminal-side application) and Java Card (card-side application).
Our implementation involves the following components:
\begin{description}
  \item[Java Card Applet] The protocol on the card-side is implemented as a
    Java Card~\cite{Chen00} applet and loaded onto a development Java Card.
    This implementation will be explained in more detail below.
  \item[Bouncy Castle Library with an extension for Pairings] The Bouncy Castle
    library\footnote{\texttt{http://www.bouncycastle.org/}} is a collection of
    cryptographic APIs for the Java and C\# programming languages. It provides
    full support for ECC and an interface to the common Java Cryptography
    Extension API. However, it does not implement pairings or elliptic curves
    over fields other than $\mathbb{F}_p$ and $\mathbb{F}_{2^m}$. Thus we have
    added our own implementations of $\mathbb{F}_{p^2}$ and
    $\mathbb{F}_{p^{12}}$, and the Tate, ate, and R-ate pairings.

    This work greatly benefited from an ate pairing in Java that Paulo Barreto
    kindly made available, and algorithms published by Hankerson et
    al.~\cite{HankersonMS09}. To minimise maintenance overhead we strived to
    keep our extensions purely \emph{on top} of the Bouncy Castle library, that
    is, we did not change anything in the original library. This allows for easy
    integration in newer library releases.
  \item[Smart Card IO Library] The standard Java Development
    Kit\footnote{Since version 6.0.} includes support for communication with
    smart cards by providing the \texttt{javax.smartcardio} package. We used it
    to talk to a Java Card smart card on which our client applet was installed.
\end{description}

[TODO: add references to source code]

\subsection{Available ECC Operations on Java Card}

In order to implement the verification protocol on Java Card we need support for
elliptic curve cryptography. In this section we summarise the available
operations and how they can be used to implement the protocol.

\subsubsection{EC Diffie-Hellman}\label{sec:ecdh-api}

This functionality is provided by the \texttt{javacard.security.KeyAgreement}
class. This class can be instantiated using the \texttt{getInstance()} method
which returns a KeyAgreement object that implements a certain algorithm. The
\texttt{generateSecret()} method can then be used to actually perform the
Diffie-Hellman operation, in our case an elliptic curve multiplication.

The standard Java Card API provides two algorithms~\cite{JavaCard-2.2.2_API_documentation}:
\begin{itemize}
  \item \texttt{ALG\_EC\_SVDP\_DH}: Elliptic curve secret value derivation
    primitive, Diffie-Hellman version, as per~\cite{IEEE_P1363}.
  \item \texttt{ALG\_EC\_SVDP\_DHC}: Elliptic curve secret value derivation
    primitive, Diffie-Hellman version, with cofactor multiplication, as
    per~\cite{IEEE_P1363}.
\end{itemize}
Unfortunately for us, the implementation of these algorithms has two drawbacks:
\begin{enumerate}
  \item According to the IEEE P1363~\cite{IEEE_P1363} standard the shared
    secret computation by means of ECSVDP-DH and ECSVDP-DHC only returns the
    $x$-coordinate of the computed point.
  \item The Java Card implementation of these algorithms computes the SHA-1
    message digest of the output of the derivation primitive to yield a 20 byte
    result~\cite{JavaCard-2.2.2_API_documentation}.
\end{enumerate}

Especially this last transformation of the result prevents it from being useful
for any further computation, other than using it as a secret key.

\paragraph{JCOP Extension}

Luckily the NXP JCOP platform contains some extensions to the standard Java Card
API. In particular this extension provides an additional algorithm:
\begin{itemize}
  \item \texttt{ALG\_EC\_SVDP\_DH\_PLAIN}: the same as
    \texttt{ALG\_EC\_SVDP\_DH} but without SHA1 post-computation.
\end{itemize}
This removes the second drawback as mentioned before and only leaves us with the
$x$-coordinate of the result instead of a point. However, the point can be
reconstructed from this coordinate using the elliptic curve formula. By putting
the $x$ value we can compute the corresponding $y$ value. The only unknown is
the sign of the $y$-coordinate, hence we end up with two candidate points for
the multiplication result.

\subsection{Public Key and Credential Blinding}

The first step of the protocol is fairly straightforward. The card has to
select the correct credential for the attribute to reveal and blind it together
with the public key. As described in Algorithm~\ref{alg:SBC-blind} this can be
done by calling the Diffie-Hellman operation once for each value. The resulting
blinded values $P_b$ and $C_b$ are then returned to the terminal.

\begin{algorithm}
  \caption{Public Key and Credential Blinding.}
  \label{alg:SBC-blind}
  \addtolength{\baselineskip}{1mm}
  \begin{algorithmic}[1]
    \Function{SBC-blind}{$b, P_c, C_a$}
      \State $P_b \gets \Call{generateSecret}{P_c, b}$
      \State $C_b \gets \Call{generateSecret}{C_a, b}$

      \Return $P_b, C_b$
    \EndFunction
  \end{algorithmic}
\end{algorithm}

\subsection{Proof of Possession of the Private Key}

Of course, when a terminal receives such a pair $P_b$, $C_b$ it should not only
check that $C_b$ is a proper signature on $P_b$, but also that the card knows
the private key corresponding to the public key $P_b$. This can be done via
standard challenge-response exchange, for example using ECDSA.

\subsubsection{Using the ECDSA Signature Scheme}

As the ECDSA digital signature algorithm is supported by the Java Card API, it
has been our first choice for implementing the challenge-response protocol to
establish proof of possession. As input for this algorithm we need the blinded
private key $k_b = b \cdot k_c$.

\begin{figure}[ht]
  \centering
  \includegraphics[scale=.4]{mscs/sbc_proof_ecdsa}
  \caption{Proof of possession of $k_b$ using ECDSA.}
  \label{fig:SBC-proof-ECDSA}
\end{figure}

Since modular multiplication is not provided by the Java Card API we used the
NatLib library developed by Hendrik Tews~\cite{TewsJacobs09}. This library
implements modular arithmetic on Java Card using byte operations and the
available RSA operations. The resulting proof of possession protocol is depicted
in Figure~\ref{fig:SBC-proof-ECDSA} and the implementation is described by
Batina et al.~\cite{BatinaHJMV10}. Unfortunately the use of the NatLib library
has an impact on the performance of the application which made us look into
other alternatives for this protocol.

\subsubsection{Using a minimal variant of the Boneh-Lynn-Shacham Signature Scheme}

[TODO: explain 'minimal' and that it is our name, not something from literature.]

Our search led us to a minimal variant of the Boneh-Lynn-Shacham signature
scheme. Since it consists of only a single point multiplication using the
private key the workload on the card is minimal. We can also exploit the
structure of the message to be signed to reduce the verification algorithm to a
single point multiplication as well. The resulting proof of possession protocol
is depicted in Figure~\ref{fig:SBC-proof-BLS}.

\begin{figure}[ht]
  \centering
  \includegraphics[scale=.4]{mscs/sbc_proof_bls}
  \caption{Proof of possession of $k_b$ using BLS.}
  \label{fig:SBC-proof-BLS}
\end{figure}

This approach requires us to compute $b \cdot k_c \cdot N$. This can be split
up in two ways, in a modular multiplication and a point multiplication or in two
point multiplications. Since the modular multiplication caused a slow-down in
the previous approach we perform the point multiplications. For this we exploit
the KeyGeneration functionality\footnote{Using the Diffie-Hellman operation
twice is not an option due to the first drawback mentioned in
Section~\ref{sec:ecdh-api}: the function does not return a point that can be used
for another point multiplication.} provided by the Java Card API. This
functionality is used to generate the blinding factor and blind the received
challenge at the same time. This allows us to simply sign the blinded challenge
with the private key using the Diffie-Hellman operation.

\subsection{Terminal Application}

The terminal application needs to cope with the shortcomings of the Java Card
applet. This comes down to the fact that the terminal has to reconstruct the
points received from the card, $P_b$, $C_b$ and $R$, before they can be
processed any further.

If we know the $x$-coordinate of a point on the curve, the square of the
corresponding $y$-coordinate is known, namely as $y^{2} = x^{3} + ax + b$.
By taking the square root of $x^{3} + ax + b$ we find either $y$ or $-y$.

This reconstruction is a simple guess work, trying different signs for the
$y$-coordinates of the points. For the proof of possession verification this is
not a real issue since this verification is only a single point multiplication,
although this is of course not optimal. For the pairing signature verification
simple guessing is not desirable. Therefore we exploit the bilinearity of the
pairing to avoid computing more than two pairings, as would be the case without
point reconstruction.

First we calculate $e_1 = e(P_b, Q_a)$ and $e_2 = e(C_b, Q)$ where we take any
sign for the $y$-coordinate of $C_b$. If $e_1 = e_2$, which happens if we have
two right, or two wrong, signs in the first parameters of the pairing, the
verification succeeds. In the remaining case, which means we took one right and
one wrong sign, we check whether $e_1 \cdot e_2 = 1$ holds. If it holds, the
verification also succeeds. This is true because of the following. If
$e_1 \neq e_2$, the error is caused by the wrong sign resulting in one pairing
being the inverse of the other, that is, $e_2 = e_1^{-1}$. Here we can use that
$e_1 \cdot e_2 = e_1 \cdot e_1^{-1} = 1$ to avoid an extra pairing calculation
for the negated point of $C_b$.

\section{Performance results}

The results of our tests are summarised in Table~\ref{tab:sbc-results}. These
values are the average of ten test runs for each configuration. The table shows
the (accumulated) duration (in milliseconds) of the requests to the card.

\begin{table}
  \centering
  \caption{Test results for various key lengths}
  \label{tab:sbc-results}
  \renewcommand{\tabcolsep}{1.25mm}
  \renewcommand{\arraystretch}{1.25}
  \begin{tabular}{| c || c | c || c |}\hline
    key length & ECDSA & minimal BLS & communication \\
    (bits) & (ms) & (ms) & (bytes) \\\hline\hline
    192 & 2748 & 787 & 155 \\\hline
    160 & 1860 & 645 & 135 \\\hline
    128 & 1599 & 535 & 115 \\\hline
  \end{tabular}
\end{table}

When we compare the two implementations it can be seen that the duration of the
ECDSA is significantly larger than the minimal BLS solution. This contrast can
be explained by the available support from the cryptographic coprocessor. For
the blinding operations in the latter the applet only uses EC primitives
provided by the coprocessor to perform the required point multiplications. The
blinding in the latter, which requires a modular multiplication, has to be
calculated \emph{without} the help of the coprocessor.

In theory it is possible to abuse the RSA cipher (and hence use the coprocessor)
to do large part of the modulo multiplication by using the fact that
$4ab = (a+b)^2 - (a-b)^2$, as in \cite{Sterckx09,TewsJacobs09}. The squares in
this equation can be performed by doing an RSA encryption\slash exponentiation
with a suitable RSA public key, that is, one with the exponent 2 and the
required modulus. The numbers $a+b$ and $a-b$ are then just messages to be
encrypted using the RSA cipher, which is provided by the Java Card API.

We tried this approach, but with no success. The main obstacle is that the RSA
cipher on the card operates only within valid bit lengths for RSA keys, starting
with 512 bit keys. Although the number to be multiplied (the message) can be any
value, the number of non-zero bits in the modulus has to be at least 488 bits
for 512 bit keys according to our tests. Since our modulus is only 192 bit long
the card refused to perform RSA encryption with such short modulus value.
However, we believe that a more flexible RSA implementation on the card would
allow this optimisation.

To get some more information about how the running time of the improved
implementation is spent on the card we measured how long it takes to perform the
individual operations. The results of these measurements can be found in
Table~\ref{tab:primitives}. The columns indicate the time needed to perform a
single operation. The processing overhead is determined by subtracting one key
generation and three key agreements from the protocol duration.

\begin{table}
  \centering
  \caption{Test results for the API primitives}
  \label{tab:primitives}
  \renewcommand{\tabcolsep}{1.25mm}
  \renewcommand{\arraystretch}{1.25}
  \begin{tabular}{| c || c | c | c |}\hline
    key length & key generation & key agreement & processing overhead \\
    (bits) & (ms) & (ms) & (ms) \\\hline
    \hline
    192 & 379 & 98 & 114 \\\hline
    160 & 307 & 78 & 104 \\\hline
    128 & 242 & 62 & 107 \\\hline
  \end{tabular}
\end{table}

On the one hand, performing a scalar point multiplication (a key agreement) is
quite efficient, using less then 100 ms for the calculation. On the other hand,
performing a scalar point multiplication, combined with generating a random
value, (a key generation) is disappointing, taking more than a factor three
longer than just the multiplication. A possible explanation is a different
calculation which explains the fact that a key generation can return a complete
point, whereas a key agreement can only return the $x$-coordinate.

A large benefit of our use of ECC is the small amount of data that needs to be
exchanged between the terminal and the card. For key lengths of 192, 160 and 128
bits the total amount of bytes exchanged is 155, 135 and 115 respectively. This
would allow an implementation to use a \emph{single} APDU pair (command and
response) for all communication. This is in strong contrast with RSA-based
protocols~\cite{Sterckx09,TewsJacobs09} which already require multiple APDUs to
transfer a single command.

%\section{MULTOS implementation??}
%
%On the MULTOS platform the ECC API is also limited to ECDH, ECDSA and key
%generation. We can, however, use the same trick as in the Java Card
%implementation to get the minimal BLS version to work. Furthermore the MULTOS
%API does provide \texttt{ModularMultiplication} operation which allows us to
%efficiently blind the private key, such that we can drop the time consuming key
%generation operation.
%
%[Unfortunately the code does not run.]